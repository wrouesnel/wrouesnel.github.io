<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="negating information entropy">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>wrouesnel_blog (old posts, page 2) | wrouesnel_blog</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://blog.wrouesnel.com/index-2.html">
<link rel="prev" href="index-3.html" type="text/html">
<link rel="next" href="index-1.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]--><link rel="stylesheet" href="assets/css/wrouesnel_blog-theme.css">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark
bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href=".">

            <span id="blog-title">wrouesnel_blog</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="categories/" class="nav-link">Tags</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
    
    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/securing-cockroachdb/" class="u-url">Securing CockroachDB</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/wrouesnel/">wrouesnel</a>
            </span></p>
            <p class="dateline">
            <a href="posts/securing-cockroachdb/" rel="bookmark">
            <time class="published dt-published" datetime="2018-05-10T02:17:00-10:00" itemprop="datePublished" title="2018-05-10 02:17">2018-05-10 02:17</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>So I just lost about 16 hours to this, and I haven't even been able to
evaluate whether it'll work for me. On the one hand I suppose I could've not
secured anything, but personally I feel you want to know what the production
configuration looks like before you evaluate (and in my case, I like to default
my docker containers to "would not be wrong to roll this into production").</p>
<p>So: how does TLS work for CockroachDB? Well the problem is CockroachDB has
atrocious logging for its TLS certificate errors in v2.0.1.</p>
<h2>The Problem</h2>
<p>The problem was basically that CockroachDB expects a very specific format
for it's x509 certificate data - outlined here <a href="https://github.com/cockroachdb/cockroach/issues/24621">https://github.com/cockroachdb/cockroach/issues/24621</a></p>
<p>I have a small utility I use for test certificates called <a href="https://github.com/wrouesnel/makecerts">makecerts</a>
which exists basically to have a much simpler static binary that does something
like <a href="https://github.com/cloudflare/cfssl">cfssl</a> but with looser defaults. But
the problem would apply to both scenarios.</p>
<p>In short: <code>organization</code> needs to be set to <code>cockroach</code> for node certificates,
and the <code>commonName</code> needs to be set to <code>node</code>. I was generating certificates with
a <code>commonName</code> of my docker-compose test network - <code>172.20.0.1</code> and the like, 
which is perfectly valid, validates correctly with the CA, and can be used to
initialize the cluster - but none of the nodes will connect to each other.</p>
<p>And as noted in the Github issue produces no logs actually describing the problem.</p>
<h2>The Solution</h2>
<p>So there you have it - with <code>makecerts</code> the line I needed for the test docker-compose
file was:</p>
<pre class="code literal-block"><span></span><code>makecerts --O<span class="o">=</span>cockroach --CN<span class="o">=</span>generated <span class="se">\</span>
    <span class="nv">172_20_0_1</span><span class="o">=</span>node,172.20.0.1,localhost,127.0.0.1 <span class="se">\</span>
    <span class="nv">172_20_0_2</span><span class="o">=</span>node,172.20.0.2,localhost,127.0.0.1 <span class="se">\</span>
    <span class="nv">172_20_0_3</span><span class="o">=</span>node,172.20.0.3,localhost,127.0.0.1 <span class="se">\</span>
    <span class="nv">172_20_0_4</span><span class="o">=</span>node,172.20.0.4,localhost,127.0.0.1 <span class="se">\</span>
    <span class="nv">172_20_0_5</span><span class="o">=</span>node,172.20.0.5,localhost,127.0.0.1 <span class="se">\</span>
    root
</code></pre>

<p>Note on how this works: this command above is saying "generate 
172_20_0_1.crt and 172_20_0_1.pem for the certificate and key respectively,
assign a commonName of <code>node</code> and then generate SANs for the commonName and
all common-separated values."</p>
<p>Since <code>makecerts</code> is simple minded it also just signs the cert for all 
use-cases - it's very much a testing tool.</p>
<p>The final docker-compose I used to get this started was:</p>
<pre class="code literal-block"><span></span><code><span class="nt">version</span><span class="p">:</span> <span class="s">'2'</span>

<span class="nt">networks</span><span class="p">:</span>
  <span class="nt">roachnet</span><span class="p">:</span>
    <span class="nt">driver</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bridge</span>
    <span class="nt">ipam</span><span class="p">:</span>
      <span class="nt">driver</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
      <span class="nt">config</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">subnet</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.20.0.0/24</span>
        <span class="nt">gateway</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.20.0.254</span>

<span class="nt">services</span><span class="p">:</span>
  <span class="nt">roach1</span><span class="p">:</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cockroachdb/cockroach:v2.0.1</span>
    <span class="nt">command</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">start --host=172.20.0.1 --logtostderr=INFO --certs-dir=/certs --join=172.20.0.1,172.20.0.2,172.20.0.3,172.20.0.4,172.20.0.5</span>
    <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./roach1:/cockroach/cockroach-data</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./172_20_0_1.crt:/certs/node.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./172_20_0_1.pem:/certs/node.key</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./root.crt:/certs/client.root.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./root.pem:/certs/client.root.key</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./generated.crt:/certs/ca.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./generated.crt:/usr/local/share/ca-certificates/ca.crt</span>
    <span class="nt">networks</span><span class="p">:</span>
      <span class="nt">roachnet</span><span class="p">:</span>
        <span class="nt">ipv4_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.20.0.1</span>

  <span class="nt">roach2</span><span class="p">:</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cockroachdb/cockroach:v2.0.1</span>
    <span class="nt">command</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">start --host=172.20.0.2 --logtostderr=INFO --certs-dir=/certs --join=172.20.0.1,172.20.0.2,172.20.0.3,172.20.0.4,172.20.0.5</span>
    <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./roach2:/cockroach/cockroach-data</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./172_20_0_2.crt:/certs/node.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./172_20_0_2.pem:/certs/node.key</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./root.crt:/certs/client.root.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./root.pem:/certs/client.root.key</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./generated.crt:/certs/ca.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./generated.crt:/usr/local/share/ca-certificates/ca.crt</span>
    <span class="nt">networks</span><span class="p">:</span>
      <span class="nt">roachnet</span><span class="p">:</span>
        <span class="nt">ipv4_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.20.0.2</span>

  <span class="nt">roach3</span><span class="p">:</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cockroachdb/cockroach:v2.0.1</span>
    <span class="nt">command</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">start --host=172.20.0.3 --logtostderr=INFO --certs-dir=/certs --join=172.20.0.1,172.20.0.2,172.20.0.3,172.20.0.4,172.20.0.5</span>
    <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./roach3:/cockroach/cockroach-data</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./172_20_0_3.crt:/certs/node.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./172_20_0_3.pem:/certs/node.key</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./root.crt:/certs/client.root.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./root.pem:/certs/client.root.key</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./generated.crt:/certs/ca.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./generated.crt:/usr/local/share/ca-certificates/ca.crt</span>
    <span class="nt">networks</span><span class="p">:</span>
      <span class="nt">roachnet</span><span class="p">:</span>
        <span class="nt">ipv4_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.20.0.3</span>

  <span class="nt">roach4</span><span class="p">:</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cockroachdb/cockroach:v2.0.1</span>
    <span class="nt">command</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">start --host=172.20.0.4 --logtostderr=INFO --certs-dir=/certs --join=172.20.0.1,172.20.0.2,172.20.0.3,172.20.0.4,172.20.0.5</span>
    <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./roach4:/cockroach/cockroach-data</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./172_20_0_4.crt:/certs/node.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./172_20_0_4.pem:/certs/node.key</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./root.crt:/certs/client.root.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./root.pem:/certs/client.root.key</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./generated.crt:/certs/ca.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./generated.crt:/usr/local/share/ca-certificates/ca.crt</span>
    <span class="nt">networks</span><span class="p">:</span>
      <span class="nt">roachnet</span><span class="p">:</span>
        <span class="nt">ipv4_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.20.0.4</span>

  <span class="nt">roach5</span><span class="p">:</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cockroachdb/cockroach:v2.0.1</span>
    <span class="nt">command</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">start --host=172.20.0.5 --logtostderr=INFO --certs-dir=/certs --join=172.20.0.1,172.20.0.2,172.20.0.3,172.20.0.4,172.20.0.5</span>
    <span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./roach5:/cockroach/cockroach-data</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./172_20_0_5.crt:/certs/node.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./172_20_0_5.pem:/certs/node.key</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./root.crt:/certs/client.root.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./root.pem:/certs/client.root.key</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./generated.crt:/certs/ca.crt</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./generated.crt:/usr/local/share/ca-certificates/ca.crt</span>
    <span class="nt">networks</span><span class="p">:</span>
      <span class="nt">roachnet</span><span class="p">:</span>
        <span class="nt">ipv4_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">172.20.0.5</span>
</code></pre>

<p>and you need to run a once-off init phase to start the cluster:</p>
<pre class="code literal-block"><span></span><code><span class="ch">#!/bin/bash</span>
docker-compose <span class="nb">exec</span> roach1 ./cockroach init --certs-dir<span class="o">=</span>/certs/ --host<span class="o">=</span><span class="m">172</span>.20.0.1
</code></pre>

<h2>A final note - why does makecerts exist?</h2>
<p>I really want to like <code>cfssl</code>, but it still just seems like too much typing for
when you're setting up test scenarios. It's a production tool for Cloudflare,
whereas the goal with <code>makecerts</code> was to make it as easy as possible to generate
TLS certs for test cases on the desktop and thus force myself to always turn
TLS on when developing - since obviously I'm always going to be using it in
production, so I should test with it.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/prometheus-reverse_exporter/" class="u-url">Prometheus reverse_exporter</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/wrouesnel/">wrouesnel</a>
            </span></p>
            <p class="dateline">
            <a href="posts/prometheus-reverse_exporter/" rel="bookmark">
            <time class="published dt-published" datetime="2018-03-29T22:13:00-11:00" itemprop="datePublished" title="2018-03-29 22:13">2018-03-29 22:13</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p><a href="https://github.com/wrouesnel/reverse_exporter/releases">Find reverse_exporter on Github Releases</a></p>
<p>In which I talk about something I made to solve a problem I had.</p>
<h2>Why</h2>
<p>I like to make my deployments of things as "appliance-like" as possible. I want
them to be plug-and-play, and have sensible defaults - in fact if possible I
want to make them production-ready "out of the box".</p>
<p>This usually involves setting up VMs or containers which include a number of
components, or a quorum of either which do the same. </p>
<p>To take a real example - I have a PowerDNS authoritative container which uses
Postgres replication for a backend. These are tightly coupled components - so
tightly that it's a lot easier to run them in the same container. PowerDNS is
nice because it has an HTTP REST API, which leads to a great turn-key DNS 
solution while retaining a lot of power - but it totally lacks an authentication
layer, so we also need to throw in nginx to provide that (and maybe something
else for auth later - for now I manage static password lists, but we might do
LDAP or something else - who knows?)</p>
<p>Obviously, we want to monitor all these components, and the way I like doing
that is with Prometheus.</p>
<h2>The Problem</h2>
<p>Prometheus exporters provide metrics, typically on an http endpoint like <code>/metrics</code>.
For our appliance like container, ideally, we want to replicate this experience.</p>
<p>The individual components in it - PowerDNS, Postgres, nginx - all have their
own exporters which provide specific metrics but also generic information about
the exporter itself - which means we have conflicting metric names for at least
the go-runtime specific metrics. And while we're at it we probably have a bunch
of random glue-code we'd like to produce some metrics about, plus some SSL
certificates we'd like to advertise expiry dates for. </p>
<p>There's also a third factor here which is important: we don't necessarily have
liberty to just open ports willy-nilly to support this - or we'd like to able
to avoid it. In the space of corporations with security policies, HTTP/HTTPS on
port 80 and 443 is easy to justify. But good luck getting another 3 ports opened
to support monitoring - oh and you'll have to put SSL and auth on those too.</p>
<h3>Solution 1 - separate endpoints</h3>
<p>In our single-container example, we only have the 1 IP for the container - but
we have nginx so we could just farm the metrics out to separate endpoints. This
works - it's my original solution. But instead of a nice, by-convention <code>/metrics</code>
endpoint we now have something like <code>/metrics/psql</code>, <code>/metrics/nginx</code>, <code>/metrics/pdns</code>.</p>
<p>Which means 3 separate entries in the Prometheus config file to scrape them, and
breaks nice features like DNS-SD to let us just discover.</p>
<p>And it feels unclean: the PowerDNS container has a bunch of things in it, but
they're all providing one-service - they're all one product. Shouldn't their
metrics all be given as one endpoint?</p>
<h3>Solution 2 - just use multiple ports</h3>
<p>This is the Prometheus way. And it would work. But it still has some of the
drawbacks above - we're still explicitly scraping 3 targets, and we're doing
some slicing on the Prometheus side to try and group these sensibly - in fact
we're requiring Prometheus to understand our architecture in detail which
shouldn't matter.</p>
<p>i.e. is the DNS container a single job with 3 endpoints in it, multiple jobs
per container? The latter feels wrong again - if our database goes sideways, its
not really a database <em>cluster</em> going down - just a single "DNS server" instance.</p>
<p>Prometheus has the idea of an "instance" tag per scraped endpoint...we'd kind of
like to support that.</p>
<h2>Solution 3 - combine the exporters into one endpoint - reverse_exporter</h2>
<p><code>reverse_exporter</code> is essentially the implementation of how we achieve this.</p>
<p>The main thing <code>reverse_exporter</code> was designed to do is receive a scrape request,
proxy it to a bunch of exporters listening on localhost behind it, and then
decode the metrics they produce so it can rewrite them with unique identifier
labels before handing them to Prometheus.</p>
<p><em>Obviously</em> metric relabelling on Prometheus can do something like this, but in
this case as solution designers/application developers/whatever we are, we want
to express an opinion on how this container runs, and simplify the overhead to
supporting it.</p>
<p>The reason we rewrite the metrics is to allow namespace collisisions - specifically
we want to ensure we can have multiple golang runtime metrics from Prometheus
live side-by-side, but still be able to separate them out in our visualiazation
tooling. We might also want to have multiples of the same application in our
container (or maybe its something like a Kubernetes pod and we want it to be
monitored like a single appliance). The point is: from a Prometheus perspective,
it all comes out looking like metrics from the 1 "instance", and gets metadata
added by Prometheus as such without any extra effort. And that's powerful - 
because it means DNS SD or service discovery works again. And it means we can
start to talk about cluster application policy in a sane way - "we'll monitor
<code>/metrics</code> on port 80 or 443 for you if it's there.</p>
<h2>Other Problems (which are solved)</h2>
<p>There were a few other common dilemmas I wanted a "correct" solution for when
I started playing around with <code>reverse_exporter</code> which it solves.</p>
<p>We don't always want to write an entire exporter for Prometheus - sometimes we
just have something tiny and fairly obvious we'd like to scrape with a text
format script. When using the Prometheus <code>node_exporter</code> you can do this with
the text collector, which will read <code>*.prom</code> files on every scrape - but you
need to setup cron to periodically update these - which can be a pain, and gives
the metrics lag.</p>
<p>What if we want to have an on-demand script?</p>
<p><code>reverse_exporter</code> allows this - you can specify a bash script, even allow
arguments to be passed via URL params, and it'll execute and collect any
metrics you write to stdout.</p>
<p>But it also protects you from the danger of naive approach here: a possible denial
of service from an overzealous or possibly malicious user sending a huge number
of requests to your script. If we just spawned a process each time, we could
quickly exhaust container or system resources. <code>reverse_exporter</code> avoids this
problem by waterfalling the results of each execution - since Prometheus regards
a scrape as a time-slice of state at the moment it gets results, we can protect
the system by queuing up inbound scrapers while the script executes, and then
sending them all the same results (provided they're happy with the wait time - 
which Prometheus is good about).</p>
<p>We avoid thrashing the system resources, and we can confidently let users and
admins reload the metrics page without bringing down our container or our host.</p>
<h2>Conclusion</h2>
<p>This post feels a bit marketing like to me, but I am pretty excited that for me
at least <code>reverse_exporter</code> works well.</p>
<p>Hopefully, it proves helpful to other Prometheus users as well!</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/s4-i9505-in-2018/" class="u-url">S4-i9505 in 2018</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/wrouesnel/">wrouesnel</a>
            </span></p>
            <p class="dateline">
            <a href="posts/s4-i9505-in-2018/" rel="bookmark">
            <time class="published dt-published" datetime="2018-01-23T23:20:00-11:00" itemprop="datePublished" title="2018-01-23 23:20">2018-01-23 23:20</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>Some notes on running a Samsung Galaxy S4 i9505 in Australia in 2018</p>
<p>My first high end phone, still perfectly capable of everything I need from a
smart phone and now dirt cheap on ebay so I'm basically going to keep buying
them till there's no more to be had (or someone releases a Spectre-immune CPU
phone I guess now).</p>
<p>Baseband: XXUGNG8
I upgraded the baseband a bunch of times including to some alleged Telstra OTA
packages, and found I lost wifi. The actual modem and APN-HLOS don't seem to
matter much but...the XXUGNG8 bootloader and related files are vitally
important to getting sound to work.</p>
<p>OS: Lineage OS
Loved Cyanogenmod, like seeing it continued. There's a patch to the SELinux
config needed on newer android to allow the proximity sensor to calibrate
properly - the symptom is an apparent freeze when making/receiving calls and
its to do with SELinux only allowing the phone to use the default prox-sensor
thresholds - which if your phone meets them, great - if not - then it will
appear broken.</p>
<p>I'm hoping to get this patched in the upstream <a href="https://review.lineageos.org/#/c/201533/">soon</a>.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/structuring-my-go-projects/" class="u-url">Structuring my Go projects</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/wrouesnel/">wrouesnel</a>
            </span></p>
            <p class="dateline">
            <a href="posts/structuring-my-go-projects/" rel="bookmark">
            <time class="published dt-published" datetime="2017-12-21T21:52:00-11:00" itemprop="datePublished" title="2017-12-21 21:52">2017-12-21 21:52</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>Recently I've been maintaining a Github repository to serve as a generic
template for my Golang projects, and its been working rather well for me.</p>
<p>The repository is here: <a href="https://github.com/wrouesnel/self-contained-go-project">Self-contained Go Project</a></p>
<p>The basic idea is that using this template, you can setup a Go project with
vendored dependencies not just for the main project but also for every tool
used in building and linting it (with the exception of <code>make</code>, <code>git</code> and a 
working Golang install). </p>
<pre class="code literal-block"><span></span><code>go get &lt;my project&gt;
<span class="nb">cd</span> <span class="nv">$GOPATH</span>/src/&lt;my project&gt;
make
</code></pre>

<p>does a production build.</p>
<h2>How to Use It</h2>
<p>Out of the box (i.e. <code>git clone https://github.com/wrouesnel/self-contained-go-project.git</code>)
on a Linux machine it should be all setup to go. I've made some effort to try
and remove Linux specific things from it, but since I don't run Mac OS or
Windows for Go development it's probably not working too well there.</p>
<p>Essentially, it'll build multi-platform, CGO-less binaries for any <code>main</code>
package you place in a folder underneath the <code>cmd</code> directory. Running <code>make binary</code>
will build all current commands for your current platform and symlink them into
the root folder, while running <code>make release</code> will build all binaries and then
create tarballs with the name and version in the <code>release</code> directory.</p>
<p>It also includes bevy of other CI-friendly commands - namely <code>make style</code> which
checks for <code>gofmt</code> and <code>goimports</code> formatting and <code>make lint</code> which runs 
<a href="https://github.com/alecthomas/gometalinter">gometalinter</a> against the entire
project.</p>
<h2>Philosophy</h2>
<p>Just looking at the commands, the main thing accomplished is a lot of use of
<code>make</code>. It's practically used for ergonomics more then utility to some level
since <code>make</code> is a familiar "build whatever this is" command in the Unix world.</p>
<p>But, importantly, <code>make</code> is used <em>correctly</em> - build dependencies are expressed
and managed in a form it understands so it only rebuilds as necessary.</p>
<p>But there is more important element, and that is not just that there is a 
Makefile but that the repository for the project, through <code>govendor</code>ing includes
not just the code but also the linting and checking tools needed to build it,
and a mechanism to update them all.</p>
<p>Under the <code>tools</code> directory we have a secondary <code>Makefile</code> which is called from
the top-level and is reposible for managing the tools. By running <code>make update</code>
here we can <code>go get</code> a new version of <code>gometalinter</code>, extract the list of tools
it runs, then automatically have them updated and installed inside the source
directory and made available to the top level <code>Makefile</code> to use to run CI tasks.</p>
<p>This combines to make project management <em>extremely</em> ergonomic in my opinion,
and avoids dragging a heavier tool like <code>Docker</code> into the mix (which often means
some uncontrolled external dependencies).</p>
<p>Basically: you check in everything your project needs to be built and run and
tested into the one Git repository, because storage is cheap but your time is
not and external dependencies can't be trusted to always exist.</p>
<h2>Conclusion</h2>
<p>It's not the be all and end all - in build tooling there never is one, but I'm
thusfar really happy with how this basic structure has turned out as I've
evolved it and it's proven relatively easy to extend when I need to (i.e.
adding more testing levels, building web assets as well with npm and including
them in the go-binary etc.)</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/tracking-down-why-my-desktop-fails-every-second-resume/" class="u-url">Tracking down why my desktop fails every second resume</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/wrouesnel/">wrouesnel</a>
            </span></p>
            <p class="dateline">
            <a href="posts/tracking-down-why-my-desktop-fails-every-second-resume/" rel="bookmark">
            <time class="published dt-published" datetime="2016-11-03T00:00:00+11:00" itemprop="datePublished" title="2016-11-03 00:00">2016-11-03 00:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>Collecting a thread to pull on...</h2>
<p>Had an interesting problem for a while now - my desktop under linux would
<em>mostly</em> suspend and resume just fine, except when it didn't. This is annoying
as I'm the type of person who likes to leave a big dev environment running and
come back to it.</p>
<p>Power management problems are the worst type of problems to debug in many ways,
so documenting any progress I made was fairly important.</p>
<p>The Ubuntu guide to kernel suspend is the most useful one I found:
<a href="https://wiki.ubuntu.com/DebuggingKernelSuspend">https://wiki.ubuntu.com/DebuggingKernelSuspend</a></p>
<p>And the important bit is this action:</p>
<pre class="code literal-block"><span></span><code>sync &amp;&amp; echo 1 &gt; /sys/power/pm_trace &amp;&amp; pm-suspend
</code></pre>

<p>This does some kernel magic which encodes suspend/resume progress into the
systems RTC clock via a hash, which allows - if things freeze - to reboot and
grab the point at which they did. You have about 3 minutes to do so after the
next boot before the data vanishes and you grab it from <code>dmesg</code>.</p>
<p>This led to an immediate reproduction - suspend-&gt;resume worked the first time,
and then hung my system on the second time. So it works, but something gets
corrupted through the process and we need to (hopefully) just reset it on 
resume to avoid the problem.</p>
<pre class="code literal-block"><span></span><code>$ dmesg <span class="p">|</span> grep -A10 Magic
<span class="o">[</span>    <span class="m">3</span>.607642<span class="o">]</span>   Magic number: <span class="m">0</span>:474:178
<span class="o">[</span>    <span class="m">3</span>.625900<span class="o">]</span>   <span class="nb">hash</span> matches /build/linux-B4zRAA/linux-4.8.0/drivers/base/power/main.c:1070
<span class="o">[</span>    <span class="m">3</span>.644583<span class="o">]</span> acpi device:0e: <span class="nb">hash</span> matches
<span class="o">[</span>    <span class="m">3</span>.663313<span class="o">]</span>  platform: <span class="nb">hash</span> matches
</code></pre>

<p>That's the easy part. What the hell does it mean?</p>
<h2>Goto the Source</h2>
<p>We get a source line out of that request, and we're running an ubuntu kernel
which has a convenient source package we can grab. So let's get that so we can
account for the Ubuntu packages:</p>
<pre class="code literal-block"><span></span><code>$ <span class="nb">cd</span> ~/tmp
$ uname -a
Linux will-desktop <span class="m">4</span>.8.0-19-generic <span class="c1">#21-Ubuntu SMP Thu Sep 29 19:39:23 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</span>
$ apt-get <span class="nb">source</span> linux-image-4.8.0-19-generic-generic
</code></pre>

<p>Which leads to this:</p>
<pre class="code literal-block"><span></span><code><span class="nv">static</span> <span class="nv">void</span> <span class="nv">async_suspend_noirq</span><span class="ss">(</span><span class="nv">void</span> <span class="o">*</span><span class="nv">data</span>, <span class="nv">async_cookie_t</span> <span class="nv">cookie</span><span class="ss">)</span>
{
    <span class="nv">struct</span> <span class="nv">device</span> <span class="o">*</span><span class="nv">dev</span> <span class="o">=</span> <span class="ss">(</span><span class="nv">struct</span> <span class="nv">device</span> <span class="o">*</span><span class="ss">)</span><span class="nv">data</span><span class="c1">;</span>
    <span class="nv">int</span> <span class="nv">error</span><span class="c1">;</span>

    <span class="nv">error</span> <span class="o">=</span> <span class="nv">__device_suspend_noirq</span><span class="ss">(</span><span class="nv">dev</span>, <span class="nv">pm_transition</span>, <span class="nv">true</span><span class="ss">)</span><span class="c1">;</span>
    <span class="k">if</span> <span class="ss">(</span><span class="nv">error</span><span class="ss">)</span> {
        <span class="nv">dpm_save_failed_dev</span><span class="ss">(</span><span class="nv">dev_name</span><span class="ss">(</span><span class="nv">dev</span><span class="ss">))</span><span class="c1">;</span>
        <span class="nv">pm_dev_err</span><span class="ss">(</span><span class="nv">dev</span>, <span class="nv">pm_transition</span>, <span class="s2">"</span><span class="s"> async</span><span class="s2">"</span>, <span class="nv">error</span><span class="ss">)</span><span class="c1">;</span>
    }

    <span class="nv">put_device</span><span class="ss">(</span><span class="nv">dev</span><span class="ss">)</span><span class="c1">;</span>
}
</code></pre>

<p>So the error line we're getting puts right on that <code>if (error)</code> line which
hopefully means this is just some device failure we can add a PM script for.</p>
<p>From <code>dmesg</code> above we've got two more things to look at - whatever <code>acpi_device:0e</code>
is and the <code>platform</code> driver for. Some googling shows that this puts us into
the category of very annoying problems: we're not even successfully getting into
the resume code, so the failure on the second resume happens very early.
<a href="https://lkml.org/lkml/2016/7/14/160">https://lkml.org/lkml/2016/7/14/160</a></p>
<h2>Time to rebuild the kernel...</h2>
<p>Which is often less work then it sounds, but judging from that LKML link it's
pretty much the only lead we have to go on since we don't have a Thinkpad but
the problem is probably suspiciously similar.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/totally-static-go-builds/" class="u-url">Totally static Go builds</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/wrouesnel/">wrouesnel</a>
            </span></p>
            <p class="dateline">
            <a href="posts/totally-static-go-builds/" rel="bookmark">
            <time class="published dt-published" datetime="2016-03-12T22:23:00-11:00" itemprop="datePublished" title="2016-03-12 22:23">2016-03-12 22:23</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>I wouldn't make a post on my blog just so I don't have to keep googling something
would I? Of course I would. It's like...95% of the reason I keep this.</p>
<p>Totally static go builds - these are <em>great</em> for running in Docker containers.
The important part is the command line to create them - it's varied a bit, but
the most thorough I've found is this (see this 
<a href="https://github.com/golang/go/issues/9344">Github Issue</a>):</p>
<pre class="code literal-block"><span></span><code><span class="nv">CGO_ENABLED</span><span class="o">=</span><span class="m">0</span> <span class="nv">GOOS</span><span class="o">=</span>linux go build -a -ldflags <span class="s1">'-extldflags "-static"'</span> .
</code></pre>

<p>This will create an "as static as possible" binary - beware linking in things
which want glibc, since pluggable name resolvers will be a problem (which you
can workaround in Docker quite well, but that's another question).</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/quickly-configuring-modelines/" class="u-url">Quickly configuring modelines?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/wrouesnel/">wrouesnel</a>
            </span></p>
            <p class="dateline">
            <a href="posts/quickly-configuring-modelines/" rel="bookmark">
            <time class="published dt-published" datetime="2016-03-12T22:22:00-11:00" itemprop="datePublished" title="2016-03-12 22:22">2016-03-12 22:22</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>Quickly configuring modelines?</h2>
<p>Something hopefully no one should ever have to do in the far distant future,
but since I insist on using old-hardware till it drops, it still comes up.</p>
<p>Working from an SSH console on an XBMC box, I was trying to tune in an elusive
1366x768 modeline for an old plasma TV.</p>
<p>The best way to do it is with xrandr these days in a <code>~/.xprofile</code> script which
is loaded on boot up.</p>
<p>To quickly go through modelines I used the following shell script:</p>
<pre class="code literal-block"><span></span><code><span class="ch">#!/bin/bash</span>
xrandr -d :0 --output VGA-0 --mode <span class="s2">"1024x768"</span>
xrandr -d :0 --delmode VGA-0 <span class="s2">"1360x768"</span>
xrandr -d :0 --rmmode <span class="s2">"1360x768"</span>
xrandr -d :0 --newmode <span class="s2">"1360x768"</span> <span class="nv">$@</span>
xrandr -d :0 --addmode VGA-0 <span class="s2">"1360x768"</span>
xrandr -d :0 --output VGA-0 --mode <span class="s2">"1360x768"</span>
</code></pre>

<p>Simply passing in a modeline when running it causes that modeline to be set and
applied to the relevant output (VGA-0) in my case.</p>
<p>i.e. <code>./tryout 84.750 1366 1480 1568 1800 768 769 776 800 -hsync +vsync</code></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/installing-the-latest-docker-release/" class="u-url">Installing the latest docker release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/wrouesnel/">wrouesnel</a>
            </span></p>
            <p class="dateline">
            <a href="posts/installing-the-latest-docker-release/" rel="bookmark">
            <time class="published dt-published" datetime="2015-09-12T03:54:00-10:00" itemprop="datePublished" title="2015-09-12 03:54">2015-09-12 03:54</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>Somehow the installation instructions for Docker never work for me and the
website is <em>surprisingly</em> cagey about the manual process.</p>
<p>It works perfectly well if you just grab the relevant bits of that script and
run them manually, but usually fails if you let it be a bit too magical.</p>
<p>To be fair, I probably have issues due to the mismatch of LSB release since I
run Mint. Still though.</p>
<p>So here's the commands for Ubuntu:</p>
<pre class="code literal-block"><span></span><code>$ apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D
$ <span class="nb">echo</span> deb https://apt.dockerproject.org/repo ubuntu-vivid main &gt; /etc/apt/sources.list.d/docker.list
$ apt-get update <span class="o">&amp;&amp;</span> apt-get install -y docker-engine
</code></pre>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/using-the-go-playground-locally/" class="u-url">Using the Go playground locally</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/wrouesnel/">wrouesnel</a>
            </span></p>
            <p class="dateline">
            <a href="posts/using-the-go-playground-locally/" rel="bookmark">
            <time class="published dt-published" datetime="2015-08-09T03:21:00-10:00" itemprop="datePublished" title="2015-08-09 03:21">2015-08-09 03:21</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>Summary</h2>
<p>I modified Rocky Bernsteins go-play to compile with go-assetfs and run from a
single executable. <a href="https://github.com/wrouesnel/go-play">Get it here!</a></p>
<h2>Why and How</h2>
<p>iPython is one of the things I love best about Python. In a dynamically typed
language its a huge benefit to be able to quickly and easily paste in chunks of
code and investigate what the actual output would be or what an error situation
would look like.</p>
<p><a href="http://golang.org">Go</a> is not dynamically typed, but many of the same issues
tend to apply - when errors rise they can be tricky to introspect without diving
through the code, and sometimes the syntax or results of a function call aren't
obvious.</p>
<p>As a learning tool, Go provides the <a href="http://play.golang.org">Go Playground</a> -
a web service which compiles and runs snippets of Go code within a sandbox,
which has proven a huge boon to the community for sharing and testing solutions
(its very popular on Stack Overflow).</p>
<p>The public Go playground is necessariy limited - and it would be nice to be able
to use Go in the same way clientside, or just without internet access.</p>
<p>Fortunately Rocky Bernstein pulled together an unrestricted copy of the Go
play ground which runs as a client-side HTML5 app. Unlike the web playground,
this allows unrestricted Go execution on your PC and full testing of things as
they would work locally. The Github export is found <a href="https://github.com/rocky/go-play">here</a>.</p>
<p>The one problem I had with this was that this version still exposed dependencies
on the location of source files outside the executable - which for a tiny tool
was kind of annoying. Fortunately this has been solved in Go for a long time -
and a little fun with <a href="https://github.com/elazarl/go-bindata-assetfs">go-bindata-assetfs</a>
yielded my own version which once built runs completely locally.</p>
<p><a href="http://github.com/wrouesnel/go-play">Get it here</a>. It's fully go-gettable too
so <code>go get github.com/wrouesnel/go-play</code> will work too.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/ssh-port-forwarding-when-allowtcpforwarding-is-disabled/" class="u-url">SSH port forwarding when port fowarding is disabled with socat and nc</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/wrouesnel/">wrouesnel</a>
            </span></p>
            <p class="dateline">
            <a href="posts/ssh-port-forwarding-when-allowtcpforwarding-is-disabled/" rel="bookmark">
            <time class="published dt-published" datetime="2015-06-07T12:07:00-10:00" itemprop="datePublished" title="2015-06-07 12:07">2015-06-07 12:07</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>The Problem</h2>
<p>You have a server you can SSH to. For whatever reason AllowTCPPortForwarding
is disabled. You need to forward a port from it to your local machine.</p>
<p>If it's any sort of standard machine, then it probably has <code>netcat</code>. It's less
likely to have the far more powerful <code>socat</code> - which we'll only need locally.</p>
<p>This tiny tip servers two lessons: (1) disabling SSH port forwarding is not a
serious security measure, and far more of an anoyance. And (2) since it's pretty
likely you still need to do whatever job you need to do, it would be nice to
have a 1-liner which will just forward the port for you</p>
<h2>The Solution</h2>
<pre class="code literal-block"><span></span><code><span class="nv">socat</span> <span class="nv">TCP</span><span class="o">-</span><span class="nv">LISTEN</span>:<span class="o">&lt;</span><span class="nv">local</span> <span class="nv">port</span><span class="o">&gt;</span>,<span class="nv">reuseaddr</span>,<span class="nv">fork</span> <span class="s2">"</span><span class="s">EXEC:ssh &lt;server&gt; nc localhost &lt;remote port&gt;</span><span class="s2">"</span>
</code></pre>

<p>It's kind of obvious if you know socat well, but half the battle is simply
knowing it's possible.</p>
<p>Obviously you can change localhost to also be a remote server. And
this is really handy if you want to do debugging since socat can echo all
data to the console for you if you want.</p>
<h2>The Lesson</h2>
<p>As I said at the start: if you have standard tools installed, or if your users
can upload new tools (which, with shell access they can), and if you don't have
firewall rules or cgroups limitations on those accounts, then stuff like
disabled port forwards <em>is not a security measure</em>.</p>
</div>
    </div>
    </article>
</div>
        <ul class="pager postindexpager clearfix">
<li class="previous"><a href="index-3.html" rel="prev">Newer posts</a></li>
            <li class="next"><a href="index-1.html" rel="next">Older posts</a></li>
        </ul>
<!--End of body content--><footer id="footer">
            Contents © 2024         <a href="mailto:wrouesnel@wrouesnel.com">Will Rouesnel</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>

        <script src="assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
